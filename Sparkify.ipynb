{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65969291",
   "metadata": {},
   "source": [
    "# Sparkify Churn\n",
    "### by Nima Sayyah\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"Sparkify.jpeg\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "* [Introduction](#int)\n",
    "* [Data Wrangling](#load)\n",
    "* [Exploratory Data Analysis](#eda)\n",
    "* [Feature Engineering](#eng)\n",
    "* [Modelling](#model)\n",
    "* [Conclusions](#con)\n",
    "\n",
    "## Introduction\n",
    "<a class=\"anchor\" id=\"int\"></a>\n",
    "\n",
    "This project will take advantage of a music app dataset similar to Spotify platform. It will use Spark to extract relevant features for predicting churn. Churn signifies the service termination. Spotting customers before they churn, the business can offer discounts and incentives for their retention to stabilise the business revenue. This workspace contains a subset (128MB) of the full dataset available (12GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e9407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pyspark \n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import isnan, count, when, col, desc, udf, col, sort_array, asc, avg\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, LinearSVC, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, PCA, RegexTokenizer, VectorAssembler, Normalizer, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98fe6465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Craeting a Spark session\n",
    "spark = SparkSession.builder.appName(\"Sparkify Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e4f1cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.host', '10.0.0.8'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/Users/NS/Documents/Data%20Science%20/Udacity/projects/Sparkify/spark-warehouse'),\n",
       " ('spark.app.id', 'local-1644705835718'),\n",
       " ('spark.app.startTime', '1644705833221'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.port', '53701'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.app.name', 'Sparkify Project')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb945a6e",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "<a class=\"anchor\" id=\"load\"></a>\n",
    "At this stage the data`mini_sparkify_event_data.json` is loaded processed and cleaned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f8d222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# loading the dataset\n",
    "df = spark.read.json(\"mini_sparkify_event_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf30b6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0794186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, artist: string, auth: string, firstName: string, gender: string, itemInSession: string, lastName: string, length: string, level: string, location: string, method: string, page: string, registration: string, sessionId: string, song: string, status: string, ts: string, userAgent: string, userId: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing basic statistics or information\n",
    "df.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dff409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
